{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c159c07",
   "metadata": {},
   "source": [
    "# ShowUI-2B Tutorial: Multimodal Analysis with FiftyOne\n",
    "\n",
    "This tutorial demonstrates how to use the ShowUI-2b vision-language models with FiftyOne as a vision-language-action model designed for GUI agents.\n",
    "\n",
    "## 1. Load a Sample Dataset\n",
    "\n",
    "First, let's load a small UI dataset from the FiftyOne Dataset Zoo.\n",
    "\n",
    "You can see some other GUI grounding datasets [here](https://huggingface.co/datasets?other=gui-grounding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "\n",
    "# Load 5 random samples from the GUI Act dataset\n",
    "dataset = load_from_hub(\n",
    "    \"Voxel51/GroundUI-18k\",\n",
    "    max_samples=200,\n",
    "    shuffle=True,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac89947",
   "metadata": {},
   "source": [
    "To get an idea of what is in this dataset you can launch the FiftyOne App to visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ca651",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec93be",
   "metadata": {},
   "source": [
    "Or just look at the first sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4bcbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open(dataset.first().filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first().instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9065f657",
   "metadata": {},
   "source": [
    "## 2. Set Up ShowUI Integration\n",
    "\n",
    "Register the ShowUI remote zoo model source and load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ffc9b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "\n",
    "# Register the model source\n",
    "foz.register_zoo_model_source(\"https://github.com/harpreetsahota204/ShowUI\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e0985",
   "metadata": {},
   "source": [
    "# Load the `ShowUI-2B` model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96097cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = foz.load_zoo_model(\n",
    "    \"showlab/ShowUI-2B\",\n",
    "    quantized=True #only for GPU\n",
    "    # install_requirements=True, #you can pass this to make sure you have all reqs installed\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16da702",
   "metadata": {},
   "source": [
    "Note that for any of the following operations you can use a Field which currently exists on your dataset, all you need to do is pass the name of that field in `prompt_field` when you call `apply_model`. For example:\n",
    "\n",
    "```python\n",
    "dataset.apply_model(model, prompt_field=\"<field-name>\", label_field=\"<label-field>\")\n",
    "```\n",
    "\n",
    "Alternatively, you can run a single prompt across all samples like so:\n",
    "\n",
    "```python\n",
    "model.prompt = \"Locate the elements of this UI that a user can interact with.\"\n",
    "dataset.apply_model(model, label_field=\"one_prompt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e560cee",
   "metadata": {},
   "source": [
    "## 1. Simple UI Grounding\n",
    "\n",
    "Ask the model to ground an element in a screenshots with a keypoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2214375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation = \"simple_grounding\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f3d8a5",
   "metadata": {},
   "source": [
    "The prompt for this operation is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d473523",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9203ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply_model(\n",
    "    model, \n",
    "    prompt_field=\"instruction\", # use a field from the dataset\n",
    "    label_field=\"simple_grounding_kps\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acbf743",
   "metadata": {},
   "source": [
    "## 2. Action Grounding\n",
    "\n",
    "Action grounding is the process of translating high-level task instructions into precise, executable UI actions with specific coordinates and parameters based on visual screen observations.\n",
    "\n",
    "In this case we are prompting the model to format the action as a dictionary with the following keys:\n",
    "`{'action': 'ACTION_TYPE', 'value': 'element', 'position': [x,y]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b254fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation = \"action_grounding\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596eb53d",
   "metadata": {},
   "source": [
    "The prompt for this operation is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd01e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply_model(\n",
    "    model, \n",
    "    prompt_field=\"instruction\", # use a field from the dataset\n",
    "    label_field=\"action_grounding_kp\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f52c6",
   "metadata": {},
   "source": [
    "## 9. View Results\n",
    "\n",
    "Examine the results for the first sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10cc0b5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dataset.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdf076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all results in the FiftyOne App\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93933402",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.freeze()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "fo_develop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
